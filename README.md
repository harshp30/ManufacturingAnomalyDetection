# Daisy Chained Classification and Segmentation Models for Anomaly Detection

**This project demonstrates an implementation of a daisy-chained inference pipeline using classification and segmentation models. The classification model first identifies the type of defect, and then the segmentation model generates a mask to highlight the defect in the image.**

---

**Technical Topics:** *Computer Vision, UNet, ResNet50, Data Augmentation, Image Segmentation, Image Classification, Model Inference*

**Tools / Technologies:** *Python, PyTorch, OpenCV, Albumentations, PIL*

**Use Case:** *Anomaly detection in manufacturing processes, particularly identifying and segmenting defects in various materials such as screws, cables, and transistors.*

---

### Performance:

Model performance based on evaluation script:

```Classification Accuracy: 0.9623```

```Segmentation Average IoU: 0.9108```

### Sample Output:

Below is an example image of the output generated by the inference daisy-chain and the real mask.

<a>
    <img src="images/result.png" alt="Inference Image" width="800" height="400">
</a>

---

### Technical Explanation:

#### Segmentation Model -- [segmentation_model.py](https://github.com/harshp30/ManufacturingAnomalyDetection/blob/main/segmentation_train/segmentation_model.py)

The segmentation script organizes and preprocesses image data, applies data augmentation, and splits the data into training, validation, and testing sets. It also defines and trains a ResNet-UNet model for image segmentation.

1. **Data Preparation:**
   - **Organize and Rename Files:** 
     - Function `organize_and_rename_files` organizes images into a consistent structure, renaming them and creating blank masks where necessary.
   - **Data Augmentation:** 
     - Function `augment_data` applies rotations, flips, color jitter, and blur using Albumentations to increase dataset variability.
   - **Data Splitting:** 
     - Function `split_data` splits the augmented data into training, validation, and test sets, ensuring each set has balanced classes.

2. **Model Architecture:**
   - **ResNet-UNet:** 
     - Combines the feature extraction capabilities of ResNet with the localization abilities of UNet, enabling precise segmentation of anomalies in images.
     - **Initialization and Layers:** 
       - Uses pre-trained ResNet-34 as the encoder, with additional convolutional layers and upsampling layers to create the decoder.
       - **Layer Details:**
         - **Layer0:** Initial convolutional and pooling layers from ResNet-34, outputting a 64-channel feature map.
         - **Layer1:** ResNet block, outputs a 64-channel feature map.
         - **Layer2:** ResNet block, outputs a 128-channel feature map.
         - **Layer3:** ResNet block, outputs a 256-channel feature map.
         - **Layer4:** ResNet block, outputs a 512-channel feature map.
         - **Upsampling and Decoding:**
           - **Conv_up3:** Combines upsampled layer4 and layer3 features, followed by double convolution.
           - **Conv_up2:** Combines upsampled Conv_up3 and layer2 features, followed by double convolution.
           - **Conv_up1:** Combines upsampled Conv_up2 and layer1 features, followed by double convolution.
           - **Conv_up0:** Combines upsampled Conv_up1 and layer0 features, followed by double convolution.
       - **Forward Pass:** 
         - Extracts features using the ResNet encoder, then upsamples and concatenates features from corresponding layers to generate the segmentation mask.

      <a>
          <img src="images/model_architecture_segmentation.png" alt="Segmentation Model" width="400" height="1500">
      </a>

3. **Training and Validation:**
   - **Custom Dataset Class:** 
     - `LeatherDataset` loads images and masks, applying specified transformations.
   - **Loss Function:** 
     - `CombinedLoss` combines BCE and Dice loss for stable training.
   - **Training Loop:** 
     - Trains the model with early stopping to avoid overfitting, saving the best model based on validation loss.

4. **Evaluation:**
   - **IoU Calculation:** 
     - Function `calculate_iou` computes the Intersection over Union metric to evaluate segmentation performance.
   - **Visualization:** 
     - Function `visualize` displays the input image, predicted mask, and true mask with IoU scores.

#### Classification Model -- [classification_model.py](https://github.com/harshp30/ManufacturingAnomalyDetection/blob/main/classification_train/classification_model.py)

The classification script handles organizing and preprocessing image data, training a ResNet-50 model, and evaluating its performance.

1. **Data Preparation:**
   - **Organize and Rename Files:** 
     - Function `organize_and_rename_files` organizes images, renames them, and saves them in the specified structure.
   - **Label Creation:**
     - Function reads labels from a file, assigns class indices, and prepares the dataset for training.

2. **Model Architecture:**
   - **CustomResNet:**
     - Custom ResNet-50 model with the final fully connected layer modified to match the number of classes.
     - **Layer Details:**
       - **Conv1:** Initial convolutional layer followed by BatchNorm and ReLU.
       - **Layer1:** ResNet block with multiple convolutional layers, outputting a 256-channel feature map.
       - **Layer2:** ResNet block with multiple convolutional layers, outputting a 512-channel feature map.
       - **Layer3:** ResNet block with multiple convolutional layers, outputting a 1024-channel feature map.
       - **Layer4:** ResNet block with multiple convolutional layers, outputting a 2048-channel feature map.
       - **Fc:** Final fully connected layer adjusted to output the desired number of classes.

      <a>
          <img src="images/model_architecture_classification.png" alt="Classification Model" width="400" height="1500">
      </a>

3. **Training and Validation:**
   - **Custom Dataset Class:**
     - `CustomDataset` loads images and labels, applying specified transformations.
   - **Training Loop:**
     - Trains the model with early stopping, saving the best model based on validation loss.

4. **Evaluation:**
   - **Accuracy Calculation:**
     - Uses accuracy score to evaluate classification performance on the test set.

#### Daisy Chained Inference -- [inference.py](https://github.com/harshp30/ManufacturingAnomalyDetection/blob/main/inference.py)

The inference script performs daisy-chained classification and segmentation on test images, saving the results.

1. **Inference Dataset:**
   - **Custom Dataset Class:**
     - `InferenceDataset` loads images and applies specified transformations for inference.

2. **Inference Process:**
   - **Load Models:**
     - Loads the pre-trained classification and segmentation models.
   - **Classification:**
     - Predicts the class of the defect using the classification model.
   - **Segmentation:**
     - Loads the appropriate segmentation model based on the classification result, generating the segmentation mask.
   - **Visualization:**
     - Function `save_results` visualizes and saves the input image, predicted mask, and classification result.

3. **Inference Execution:**
   - **Main Function:**
     - Performs inference on the dataset, chaining the classification and segmentation models to process each image and save the results.

---

### Next Steps:

- Expand the project to include more types of defects and materials.
- Improve the data augmentation pipeline to increase model robustness.
- Implement real-time inference for streaming data in manufacturing environments.

---

### Citations:

Dataset Credit:

```
Paul Bergmann, Kilian Batzner, Michael Fauser, David Sattlegger, Carsten Steger: The MVTec Anomaly Detection Dataset: A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection; in: International Journal of Computer Vision 129(4):1038-1059, 2021, DOI: 10.1007/s11263-020-01400-4.

Paul Bergmann, Michael Fauser, David Sattlegger, Carsten Steger: MVTec AD â€” A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection; in: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 9584-9592, 2019, DOI: 10.1109/CVPR.2019.00982.
```
